import os
import sys
import json
import uuid
import logging
import asyncio
from datetime import datetime
from typing import Dict, Any, List, Optional, Set

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„ï¼Œç¡®ä¿æ¨¡å—å¯¼å…¥æ­£å¸¸
sys.path.append(os.path.dirname(__file__))

from astrbot.api.star import Context, Star, register
from astrbot.api.event import AstrMessageEvent, filter
from astrbot.api import logger as astrbot_logger

class MemoryAssociationManager:
    """è®°å¿†å…³è”ç®¡ç†å™¨"""
    def __init__(self, storage_path: str):
        self.storage_path = storage_path
        self.associations = {}  # {memory_id: {related_id: strength}}
        self.load_associations()
    
    def load_associations(self):
        """åŠ è½½å…³è”æ•°æ®"""
        try:
            assoc_path = os.path.join(self.storage_path, "associations.json")
            if os.path.exists(assoc_path):
                with open(assoc_path, 'r', encoding='utf-8') as f:
                    self.associations = json.load(f)
                astrbot_logger.info(f"Loaded {sum(len(v) for v in self.associations.values())} associations")
        except Exception as e:
            astrbot_logger.error(f"Failed to load associations: {e}")
            self.associations = {}
    
    def save_associations(self):
        """ä¿å­˜å…³è”æ•°æ®"""
        try:
            assoc_path = os.path.join(self.storage_path, "associations.json")
            with open(assoc_path, 'w', encoding='utf-8') as f:
                json.dump(self.associations, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            astrbot_logger.error(f"Failed to save associations: {e}")
            return False
    
    def add_association(self, memory_id: str, related_id: str, strength: float = 1.0):
        """æ·»åŠ è®°å¿†å…³è”"""
        if memory_id not in self.associations:
            self.associations[memory_id] = {}
        if related_id not in self.associations:
            self.associations[related_id] = {}
        
        self.associations[memory_id][related_id] = strength
        self.associations[related_id][memory_id] = strength
        
        self.save_associations()
        return True
    
    def remove_association(self, memory_id: str, related_id: str):
        """ç§»é™¤è®°å¿†å…³è”"""
        if memory_id in self.associations and related_id in self.associations[memory_id]:
            del self.associations[memory_id][related_id]
        if related_id in self.associations and memory_id in self.associations[related_id]:
            del self.associations[related_id][memory_id]
        
        self.save_associations()
        return True
    
    def get_associated_memories(self, memory_id: str, limit: int = 5) -> List[Dict[str, Any]]:
        """è·å–å…³è”è®°å¿†"""
        if memory_id not in self.associations:
            return []
        
        associations = []
        for related_id, strength in self.associations[memory_id].items():
            associations.append({
                "memory_id": related_id,
                "strength": strength
            })
        
        # æŒ‰å…³è”å¼ºåº¦æ’åº
        associations.sort(key=lambda x: x["strength"], reverse=True)
        return associations[:limit]
    
    def auto_create_associations(self, memory_id: str, content: str, all_memories: Dict[str, Any], threshold: float = 0.3):
        """è‡ªåŠ¨åˆ›å»ºå…³è”"""
        try:
            # ç®€å•çš„åŸºäºå…³é”®è¯çš„å…³è”
            keywords = self._extract_keywords(content)
            created_count = 0
            
            for other_id, other_memory in all_memories.items():
                if other_id == memory_id:
                    continue
                
                other_content = other_memory.get("content", "")
                other_keywords = self._extract_keywords(other_content)
                
                # è®¡ç®—å…³é”®è¯é‡å åº¦
                overlap = len(set(keywords) & set(other_keywords))
                total_unique = len(set(keywords) | set(other_keywords))
                
                if total_unique > 0:
                    similarity = overlap / total_unique
                    if similarity >= threshold:
                        self.add_association(memory_id, other_id, similarity)
                        created_count += 1
            
            return created_count
        except Exception as e:
            astrbot_logger.error(f"Auto create associations failed: {e}")
            return 0
    
    def _extract_keywords(self, text: str) -> List[str]:
        """æå–å…³é”®è¯"""
        try:
            import jieba.analyse
            return jieba.analyse.extract_tags(text, topK=10)
        except:
            # ç®€å•çš„åˆ†è¯åå¤‡æ–¹æ¡ˆ
            return [word for word in text.split() if len(word) > 1]

class AutoMemoryExtractor:
    """è‡ªåŠ¨è®°å¿†æå–å™¨"""
    def __init__(self, min_importance: float = 0.3):
        self.min_importance = min_importance
    
    def extract_from_conversation(self, message: str, conversation_history: List[Dict] = None) -> List[Dict[str, Any]]:
        """ä»å¯¹è¯ä¸­æå–è®°å¿†"""
        memories = []
        
        # æ£€æµ‹å¯èƒ½çš„é‡è¦ä¿¡æ¯
        importance = self._calculate_importance(message, conversation_history)
        
        if importance >= self.min_importance:
            memory_type = self._classify_message_type(message)
            
            memory = {
                "content": message,
                "importance": importance,
                "type": memory_type,
                "source": "auto_extract",
                "extracted_at": datetime.now().isoformat()
            }
            memories.append(memory)
        
        return memories
    
    def _calculate_importance(self, message: str, conversation_history: List[Dict] = None) -> float:
        """è®¡ç®—æ¶ˆæ¯é‡è¦æ€§"""
        importance = 0.1
        
        # åŒ…å«ä¸ªäººä¿¡æ¯
        personal_indicators = ["æˆ‘", "æˆ‘çš„", "è‡ªå·±", "ä¸ªäºº"]
        if any(indicator in message for indicator in personal_indicators):
            importance += 0.3
        
        # åŒ…å«åå¥½ä¿¡æ¯
        preference_indicators = ["å–œæ¬¢", "è®¨åŒ", "çˆ±", "æ¨", "åå¥½", "ä¹ æƒ¯"]
        if any(indicator in message for indicator in preference_indicators):
            importance += 0.4
        
        # åŒ…å«äº‹å®ä¿¡æ¯
        fact_indicators = ["æ˜¯", "æœ‰", "åœ¨", "å±äº", "çŸ¥é“", "è®°å¾—"]
        if any(indicator in message for indicator in fact_indicators):
            importance += 0.2
        
        # åŒ…å«æ—¶é—´ä¿¡æ¯
        time_indicators = ["æ˜¨å¤©", "ä»Šå¤©", "æ˜å¤©", "ä¸Šå‘¨", "å»å¹´"]
        if any(indicator in message for indicator in time_indicators):
            importance += 0.2
        
        # å¯¹è¯ä¸Šä¸‹æ–‡å¢å¼º
        if conversation_history:
            # æ£€æŸ¥æ˜¯å¦æ˜¯é‡è¦é—®é¢˜çš„å›ç­”
            last_user_msg = None
            for msg in reversed(conversation_history):
                if msg.get("role") == "user":
                    last_user_msg = msg.get("content", "")
                    break
            
            if last_user_msg and any(q in last_user_msg for q in ["ä»€ä¹ˆ", "ä¸ºä»€ä¹ˆ", "æ€ä¹ˆ", "å¦‚ä½•", "å—ï¼Ÿ"]):
                importance += 0.3
        
        return min(importance, 1.0)
    
    def _classify_message_type(self, message: str) -> str:
        """åˆ†ç±»æ¶ˆæ¯ç±»å‹"""
        message_lower = message.lower()
        
        if any(word in message_lower for word in ['å–œæ¬¢', 'è®¨åŒ', 'çˆ±', 'æ¨', 'åå¥½']):
            return 'preference'
        elif any(word in message_lower for word in ['è®¤ä¸º', 'è§‰å¾—', 'æƒ³', 'åº”è¯¥']):
            return 'opinion'
        elif any(word in message_lower for word in ['æ˜¨å¤©', 'ä»Šå¤©', 'æ˜å¤©', 'å°æ—¶', 'åˆ†é’Ÿ']):
            return 'event'
        elif any(word in message_lower for word in ['æ˜¯', 'æœ‰', 'åœ¨', 'å±äº']):
            return 'fact'
        else:
            return 'other'

class DataExportManager:
    """æ•°æ®å¯¼å‡ºç®¡ç†å™¨"""
    def __init__(self, storage_path: str):
        self.storage_path = storage_path
    
    def export_memories(self, memories: Dict[str, Any], format: str = "json") -> str:
        """å¯¼å‡ºè®°å¿†æ•°æ®"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            if format == "json":
                filename = f"memories_export_{timestamp}.json"
                filepath = os.path.join(self.storage_path, filename)
                
                with open(filepath, 'w', encoding='utf-8') as f:
                    json.dump(memories, f, ensure_ascii=False, indent=2)
                
                return filepath
            
            elif format == "csv":
                import csv
                filename = f"memories_export_{timestamp}.csv"
                filepath = os.path.join(self.storage_path, filename)
                
                with open(filepath, 'w', encoding='utf-8', newline='') as f:
                    writer = csv.writer(f)
                    writer.writerow(["ID", "Content", "Type", "Importance", "Created At", "Last Accessed"])
                    
                    for memory_id, memory in memories.items():
                        writer.writerow([
                            memory_id,
                            memory.get("content", ""),
                            memory.get("type", ""),
                            memory.get("importance", 0),
                            memory.get("created_at", ""),
                            memory.get("last_accessed", "")
                        ])
                
                return filepath
            
            else:
                raise ValueError(f"Unsupported format: {format}")
                
        except Exception as e:
            astrbot_logger.error(f"Export memories failed: {e}")
            return None
    
    def import_memories(self, filepath: str, format: str = "json") -> Dict[str, Any]:
        """å¯¼å…¥è®°å¿†æ•°æ®"""
        try:
            if format == "json":
                with open(filepath, 'r', encoding='utf-8') as f:
                    return json.load(f)
            
            elif format == "csv":
                import csv
                memories = {}
                
                with open(filepath, 'r', encoding='utf-8') as f:
                    reader = csv.DictReader(f)
                    for row in reader:
                        memory_id = row.get("ID", str(uuid.uuid4()))
                        memory = {
                            "id": memory_id,
                            "content": row.get("Content", ""),
                            "type": row.get("Type", "other"),
                            "importance": float(row.get("Importance", 0.5)),
                            "created_at": row.get("Created At", datetime.now().isoformat()),
                            "last_accessed": datetime.now().isoformat(),
                            "access_count": 0
                        }
                        memories[memory_id] = memory
                
                return memories
            
            else:
                raise ValueError(f"Unsupported format: {format}")
                
        except Exception as e:
            astrbot_logger.error(f"Import memories failed: {e}")
            return {}

class MemoryOrganizer:
    """è®°å¿†æ¢³ç†å™¨ - ä½¿ç”¨AIæ¨¡å‹æ™ºèƒ½æ•´ç†è®°å¿†"""
    
    def __init__(self, context: Context):
        self.context = context
        self.available_models = {}
        self._discover_models()
    
    def _discover_models(self):
        """å‘ç°å¯ç”¨çš„AIæ¨¡å‹"""
        try:
            # è·å–æ‰€æœ‰å¯ç”¨çš„LLMæä¾›å•†
            providers = self.context.get_all_providers()
            astrbot_logger.info(f"Found {len(providers)} providers in context")
            
            for provider in providers:
                provider_id = getattr(provider, 'id', 'unknown')
                provider_name = getattr(provider, 'name', 'Unknown')
                self.available_models[provider_id] = {
                    'name': provider_name,
                    'provider': provider
                }
                astrbot_logger.info(f"Discovered model: {provider_id} - {provider_name}")
            
            astrbot_logger.info(f"Total discovered models: {len(self.available_models)}")
        except Exception as e:
            astrbot_logger.error(f"Failed to discover models: {e}")
    
    async def organize_memories(self, memories: List[Dict[str, Any]], 
                              model_id: str = None,
                              tasks: List[str] = None) -> Dict[str, Any]:
        """ä½¿ç”¨AIæ¨¡å‹æ¢³ç†è®°å¿†"""
        if not tasks:
            tasks = ["categorize", "summarize", "find_duplicates", "suggest_associations", "suggest_importance"]
        
        provider = None
        if model_id and model_id in self.available_models:
            provider = self.available_models[model_id]['provider']
            astrbot_logger.info(f"Using specified model: {model_id}")
        else:
            # ä½¿ç”¨é»˜è®¤æä¾›å•†
            provider = self.context.get_using_provider()
            if provider:
                astrbot_logger.info(f"Using default provider: {getattr(provider, 'name', 'Unknown')}")
            else:
                astrbot_logger.warning("No default provider available")
        
        if not provider:
            return {"error": "No available AI model found"}
        
        try:
            results = {}
            
            # å‡†å¤‡è®°å¿†æ–‡æœ¬
            memory_texts = []
            for memory in memories:
                memory_texts.append(f"è®°å¿†ID: {memory.get('id', 'unknown')}")
                memory_texts.append(f"å†…å®¹: {memory.get('content', '')}")
                memory_texts.append(f"ç±»å‹: {memory.get('type', 'unknown')}")
                memory_texts.append(f"é‡è¦æ€§: {memory.get('importance', 0.5)}")
                memory_texts.append("---")
            
            memory_context = "\n".join(memory_texts)
            
            # æ ¹æ®ä»»åŠ¡ç”Ÿæˆæç¤º
            for task in tasks:
                if task == "categorize":
                    prompt = self._build_categorize_prompt(memory_context)
                    response = await provider.text_chat(prompt=prompt)
                    results["categorization"] = self._parse_categorization_response(response.content)
                
                elif task == "summarize":
                    prompt = self._build_summarize_prompt(memory_context)
                    response = await provider.text_chat(prompt=prompt)
                    results["summary"] = response.content
                
                elif task == "find_duplicates":
                    prompt = self._build_duplicate_prompt(memory_context)
                    response = await provider.text_chat(prompt=prompt)
                    results["duplicates"] = self._parse_duplicate_response(response.content)
                
                elif task == "suggest_associations":
                    prompt = self._build_association_prompt(memory_context)
                    response = await provider.text_chat(prompt=prompt)
                    results["associations"] = self._parse_association_response(response.content)
                
                elif task == "suggest_importance":
                    prompt = self._build_importance_prompt(memory_context)
                    response = await provider.text_chat(prompt=prompt)
                    results["importance_suggestions"] = self._parse_importance_response(response.content)
            
            return results
            
        except Exception as e:
            astrbot_logger.error(f"Memory organization failed: {e}")
            return {"error": f"Organization failed: {str(e)}"}
    
    def _build_categorize_prompt(self, memory_context: str) -> str:
        """æ„å»ºåˆ†ç±»æç¤º"""
        return f"""è¯·åˆ†æä»¥ä¸‹è®°å¿†å†…å®¹ï¼Œå¹¶å»ºè®®æ›´å¥½çš„åˆ†ç±»æ–¹å¼ã€‚å½“å‰åˆ†ç±»æœ‰ï¼šäº‹å®(fact)ã€è§‚ç‚¹(opinion)ã€ç”¨æˆ·åå¥½(preference)ã€äº‹ä»¶(event)ã€å…¶ä»–(other)ã€‚

è¯·ä¸ºæ¯æ®µè®°å¿†å»ºè®®æ›´å‡†ç¡®çš„åˆ†ç±»ï¼Œå¹¶å¯ä»¥å»ºè®®æ–°çš„åˆ†ç±»ç±»åˆ«ã€‚

è®°å¿†å†…å®¹ï¼š
{memory_context}

è¯·ä»¥JSONæ ¼å¼å›å¤ï¼ŒåŒ…å«ï¼š
1. memory_id: è®°å¿†ID
2. suggested_category: å»ºè®®çš„åˆ†ç±»
3. reason: åˆ†ç±»ç†ç”±
4. confidence: ç½®ä¿¡åº¦(0-1)

æ ¼å¼ç¤ºä¾‹ï¼š
[
  {{
    "memory_id": "è®°å¿†ID",
    "suggested_category": "æ–°åˆ†ç±»",
    "reason": "åˆ†ç±»ç†ç”±",
    "confidence": 0.9
  }}
]"""
    
    def _build_summarize_prompt(self, memory_context: str) -> str:
        """æ„å»ºæ€»ç»“æç¤º"""
        return f"""è¯·æ€»ç»“ä»¥ä¸‹è®°å¿†åº“çš„ä¸»è¦å†…å®¹ã€ä¸»é¢˜åˆ†å¸ƒå’Œå…³é”®ä¿¡æ¯ï¼š

{memory_context}

è¯·æä¾›ï¼š
1. ä¸»è¦ä¸»é¢˜å’Œç±»åˆ«
2. æœ€é‡è¦çš„å‡ ä¸ªè®°å¿†ç‚¹
3. è®°å¿†åº“çš„æ•´ä½“ç‰¹ç‚¹
4. å»ºè®®çš„æ”¹è¿›æ–¹å‘"""
    
    def _build_duplicate_prompt(self, memory_context: str) -> str:
        """æ„å»ºé‡å¤æ£€æµ‹æç¤º"""
        return f"""è¯·åˆ†æä»¥ä¸‹è®°å¿†å†…å®¹ï¼Œæ‰¾å‡ºå¯èƒ½é‡å¤æˆ–é«˜åº¦ç›¸ä¼¼çš„è®°å¿†å¯¹ï¼š

{memory_context}

è¯·ä»¥JSONæ ¼å¼å›å¤å¯èƒ½é‡å¤çš„è®°å¿†å¯¹ï¼š
[
  {{
    "memory_id_1": "è®°å¿†ID1",
    "memory_id_2": "è®°å¿†ID2", 
    "similarity_reason": "é‡å¤åŸå› ",
    "suggestion": "å¤„ç†å»ºè®®(åˆå¹¶/åˆ é™¤/ä¿ç•™)"
  }}
]"""
    
    def _build_association_prompt(self, memory_context: str) -> str:
        """æ„å»ºå…³è”å»ºè®®æç¤º"""
        return f"""è¯·åˆ†æä»¥ä¸‹è®°å¿†å†…å®¹ï¼Œå»ºè®®åº”è¯¥å»ºç«‹å…³è”çš„è®°å¿†å¯¹ï¼š

{memory_context}

è¯·ä»¥JSONæ ¼å¼å›å¤å»ºè®®çš„å…³è”ï¼š
[
  {{
    "memory_id_1": "è®°å¿†ID1",
    "memory_id_2": "è®°å¿†ID2",
    "relation_type": "å…³è”ç±»å‹(å¦‚: å› æœå…³ç³»/æ—¶é—´é¡ºåº/ä¸»é¢˜ç›¸å…³ç­‰)",
    "relation_strength": å…³è”å¼ºåº¦(0-1),
    "reason": "å…³è”ç†ç”±"
  }}
]"""
    
    def _build_importance_prompt(self, memory_context: str) -> str:
        """æ„å»ºé‡è¦æ€§è¯„ä¼°æç¤º"""
        return f"""è¯·é‡æ–°è¯„ä¼°ä»¥ä¸‹è®°å¿†çš„é‡è¦æ€§(0-1åˆ†)ï¼Œ1åˆ†æœ€é‡è¦ï¼š

{memory_context}

è¯·ä»¥JSONæ ¼å¼å›å¤é‡è¦æ€§å»ºè®®ï¼š
[
  {{
    "memory_id": "è®°å¿†ID",
    "suggested_importance": æ–°é‡è¦æ€§åˆ†æ•°,
    "reason": "è°ƒæ•´ç†ç”±"
  }}
]"""
    
    def _parse_categorization_response(self, response: str) -> List[Dict]:
        """è§£æåˆ†ç±»å“åº”"""
        try:
            # å°è¯•æå–JSONéƒ¨åˆ†
            import re
            json_match = re.search(r'\[.*\]', response, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            else:
                # å¦‚æœæ‰¾ä¸åˆ°JSONï¼Œè¿”å›åŸå§‹å“åº”
                return [{"raw_response": response}]
        except:
            return [{"raw_response": response}]
    
    def _parse_duplicate_response(self, response: str) -> List[Dict]:
        """è§£æé‡å¤æ£€æµ‹å“åº”"""
        return self._parse_categorization_response(response)
    
    def _parse_association_response(self, response: str) -> List[Dict]:
        """è§£æå…³è”å»ºè®®å“åº”"""
        return self._parse_categorization_response(response)
    
    def _parse_importance_response(self, response: str) -> List[Dict]:
        """è§£æé‡è¦æ€§è¯„ä¼°å“åº”"""
        return self._parse_categorization_response(response)
    
    def get_available_models(self) -> Dict[str, Any]:
        """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
        return self.available_models

class EnhancedMemoryManager:
    """å¢å¼ºè®°å¿†ç®¡ç†å™¨"""
    def __init__(self, storage_path: str, context: Context = None):
        self.storage_path = storage_path
        self.memories = {}
        self.embedding_model = None
        self.association_manager = MemoryAssociationManager(storage_path)
        self.extractor = AutoMemoryExtractor()
        self.export_manager = DataExportManager(storage_path)
        self.organizer = MemoryOrganizer(context) if context else None
        
        # ç¡®ä¿å­˜å‚¨è·¯å¾„å­˜åœ¨
        self._ensure_storage_path()
        self._initialize_components()
        self.load_memories()
    
    def _ensure_storage_path(self):
        """ç¡®ä¿å­˜å‚¨è·¯å¾„å­˜åœ¨"""
        try:
            # è§„èŒƒåŒ–è·¯å¾„ï¼Œé¿å…é‡å¤çš„dataç›®å½•
            normalized_path = os.path.normpath(self.storage_path)
            os.makedirs(normalized_path, exist_ok=True)
            astrbot_logger.info(f"Created storage path: {normalized_path}")
        except Exception as e:
            astrbot_logger.error(f"Failed to create storage path: {e}")
            import tempfile
            self.storage_path = os.path.join(tempfile.gettempdir(), "enhanced_memory")
            os.makedirs(self.storage_path, exist_ok=True)
            astrbot_logger.info(f"Using fallback storage: {self.storage_path}")
    
    def _initialize_components(self):
        """åˆå§‹åŒ–ç»„ä»¶"""
        # æ£€æŸ¥å¹¶åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        try:
            from sentence_transformers import SentenceTransformer
            self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
            astrbot_logger.info("Embedding model initialized")
        except ImportError:
            astrbot_logger.warning("sentence-transformers not available, semantic search disabled")
        except Exception as e:
            astrbot_logger.error(f"Failed to initialize embedding model: {e}")
    
    def load_memories(self):
        """åŠ è½½è®°å¿†"""
        try:
            memories_path = os.path.join(self.storage_path, "memories.json")
            if os.path.exists(memories_path):
                with open(memories_path, 'r', encoding='utf-8') as f:
                    self.memories = json.load(f)
                astrbot_logger.info(f"Loaded {len(self.memories)} memories")
            else:
                self.memories = {}
                astrbot_logger.info("No existing memories found, starting fresh")
        except Exception as e:
            astrbot_logger.error(f"Failed to load memories: {e}")
            self.memories = {}
    
    def save_memories(self):
        """ä¿å­˜è®°å¿†"""
        try:
            memories_path = os.path.join(self.storage_path, "memories.json")
            with open(memories_path, 'w', encoding='utf-8') as f:
                json.dump(self.memories, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            astrbot_logger.error(f"Failed to save memories: {e}")
            return False
    
    def add_memory(self, content: str, importance: float = 0.5, memory_type: str = None, 
                  auto_associate: bool = True, **kwargs):
        """æ·»åŠ è®°å¿†"""
        memory_id = str(uuid.uuid4())
        
        # è‡ªåŠ¨åˆ†ç±»è®°å¿†ç±»å‹
        if memory_type is None:
            memory_type = self._classify_memory_type(content)
        
        memory_data = {
            "id": memory_id,
            "content": content,
            "importance": importance,
            "type": memory_type,
            "created_at": datetime.now().isoformat(),
            "last_accessed": datetime.now().isoformat(),
            "access_count": 0
        }
        
        # å°è¯•æå–å…³é”®è¯
        try:
            import jieba.analyse
            keywords = jieba.analyse.extract_tags(content, topK=5)
            memory_data["keywords"] = keywords
        except ImportError:
            memory_data["keywords"] = []
        
        self.memories[memory_id] = memory_data
        self.save_memories()
        
        # è‡ªåŠ¨åˆ›å»ºå…³è”
        if auto_associate and len(self.memories) > 1:
            created_count = self.association_manager.auto_create_associations(memory_id, content, self.memories)
            astrbot_logger.info(f"Auto created {created_count} associations for memory {memory_id}")
        
        astrbot_logger.info(f"Added memory: {content[:50]}...")
        return memory_id
    
    def delete_memory(self, memory_id: str):
        """åˆ é™¤è®°å¿†"""
        if memory_id in self.memories:
            # ç§»é™¤å…³è”
            if memory_id in self.association_manager.associations:
                related_ids = list(self.association_manager.associations[memory_id].keys())
                for related_id in related_ids:
                    self.association_manager.remove_association(memory_id, related_id)
                del self.association_manager.associations[memory_id]
            
            # ç§»é™¤è®°å¿†
            del self.memories[memory_id]
            self.save_memories()
            self.association_manager.save_associations()
            return True
        return False
    
    def update_memory(self, memory_id: str, **kwargs):
        """æ›´æ–°è®°å¿†"""
        if memory_id in self.memories:
            memory = self.memories[memory_id]
            memory.update(kwargs)
            memory["last_accessed"] = datetime.now().isoformat()
            self.save_memories()
            return True
        return False
    
    def _classify_memory_type(self, content: str) -> str:
        """åˆ†ç±»è®°å¿†ç±»å‹"""
        content_lower = content.lower()
        
        if any(word in content_lower for word in ['å–œæ¬¢', 'è®¨åŒ', 'çˆ±', 'æ¨', 'åå¥½']):
            return 'preference'
        elif any(word in content_lower for word in ['è®¤ä¸º', 'è§‰å¾—', 'æƒ³', 'åº”è¯¥']):
            return 'opinion'
        elif any(word in content_lower for word in ['æ˜¨å¤©', 'ä»Šå¤©', 'æ˜å¤©', 'å°æ—¶', 'åˆ†é’Ÿ']):
            return 'event'
        elif any(word in content_lower for word in ['æ˜¯', 'æœ‰', 'åœ¨', 'å±äº']):
            return 'fact'
        else:
            return 'other'
        
def search_memories(self, query: str, limit: int = 5, use_semantic: bool = True, 
                   include_associated: bool = False, **kwargs):
    """æœç´¢è®°å¿† - ä¿®å¤ç‰ˆ"""
    results = []
    
    # é¦–å…ˆè¿›è¡Œå…³é”®è¯æœç´¢ï¼ˆç¡®ä¿åŸºç¡€æœç´¢å·¥ä½œï¼‰
    for memory in self.memories.values():
        content = memory.get("content", "").lower()
        query_lower = query.lower()
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…
        if query_lower in content:
            memory_copy = memory.copy()
            memory_copy["match_type"] = "keyword"
            memory_copy["similarity"] = 1.0
            results.append(memory_copy)
    
    # å¦‚æœå¯ç”¨äº†è¯­ä¹‰æœç´¢ä¸”æœ‰åµŒå…¥æ¨¡å‹ï¼Œå°è¯•è¯­ä¹‰æœç´¢
    if use_semantic and self.embedding_model is not None and not results:
        try:
            semantic_results = self._semantic_search(query, limit * 2)
            for result in semantic_results:
                memory_id = result["memory_id"]
                if memory_id in self.memories:
                    memory = self.memories[memory_id].copy()
                    memory["similarity"] = result["similarity"]
                    memory["match_type"] = "semantic"
                    results.append(memory)
        except Exception as e:
            astrbot_logger.error(f"è¯­ä¹‰æœç´¢å¤±è´¥ï¼Œä½¿ç”¨å…³é”®è¯æœç´¢: {e}")
    
    # åŒ…å«å…³è”è®°å¿†
    if include_associated and results:
        all_results = results.copy()
        for memory in results:
            associated = self.association_manager.get_associated_memories(memory["id"], limit=3)
            for assoc in associated:
                assoc_id = assoc["memory_id"]
                if assoc_id in self.memories and assoc_id not in [r["id"] for r in all_results]:
                    assoc_memory = self.memories[assoc_id].copy()
                    assoc_memory["association_strength"] = assoc["strength"]
                    assoc_memory["match_type"] = "associated"
                    all_results.append(assoc_memory)
        results = all_results
    
    # æŒ‰é‡è¦æ€§æ’åº
    results.sort(key=lambda x: x.get("importance", 0), reverse=True)
    
    # è®°å½•æœç´¢ç»“æœç”¨äºè°ƒè¯•
    astrbot_logger.info(f"æœç´¢ '{query}' æ‰¾åˆ° {len(results)} æ¡ç»“æœ")
    for result in results[:3]:  # åªè®°å½•å‰3æ¡
        astrbot_logger.info(f"  åŒ¹é…: {result.get('content', '')[:50]}... (ç±»å‹: {result.get('match_type', 'unknown')})")
    
    return results[:limit]
    
    def _semantic_search(self, query: str, k: int = 5):
        """è¯­ä¹‰æœç´¢"""
        if not self.embedding_model:
            return []
        
        try:
            import numpy as np
            
            # ç”ŸæˆæŸ¥è¯¢å‘é‡
            query_embedding = self.embedding_model.encode([query])
            query_embedding = np.array(query_embedding, dtype='float32')
            
            # æ„å»ºä¸´æ—¶ç´¢å¼•è¿›è¡Œæœç´¢
            embeddings = []
            memory_ids = []
            
            for memory_id, memory in self.memories.items():
                memory_embedding = self.embedding_model.encode([memory["content"]])
                embeddings.append(memory_embedding[0])
                memory_ids.append(memory_id)
            
            if not embeddings:
                return []
            
            embeddings = np.array(embeddings, dtype='float32')
            
            # ä½¿ç”¨FAISSå¦‚æœå¯ç”¨ï¼Œå¦åˆ™ä½¿ç”¨numpyè®¡ç®—
            try:
                import faiss
                index = faiss.IndexFlatL2(embeddings.shape[1])
                index.add(embeddings)
                distances, indices = index.search(query_embedding, min(k, len(embeddings)))
            except ImportError:
                # ä½¿ç”¨numpyè®¡ç®—ç›¸ä¼¼åº¦
                distances = np.linalg.norm(embeddings - query_embedding, axis=1)
                indices = np.argsort(distances)[:k]
                distances = distances[indices].reshape(1, -1)
                indices = indices.reshape(1, -1)
            
            results = []
            for i, idx in enumerate(indices[0]):
                if idx < len(memory_ids):
                    results.append({
                        "memory_id": memory_ids[idx],
                        "similarity": 1.0 / (1.0 + distances[0][i]),
                        "distance": distances[0][i]
                    })
            
            return results
            
        except Exception as e:
            astrbot_logger.error(f"Semantic search error: {e}")
            return []
    
    def auto_extract_from_message(self, message: str, conversation_history: List[Dict] = None):
        """ä»æ¶ˆæ¯è‡ªåŠ¨æå–è®°å¿†"""
        extracted_memories = self.extractor.extract_from_conversation(message, conversation_history)
        memory_ids = []
        
        for memory_data in extracted_memories:
            memory_id = self.add_memory(
                content=memory_data["content"],
                importance=memory_data["importance"],
                memory_type=memory_data["type"],
                auto_associate=True
            )
            memory_ids.append(memory_id)
        
        return memory_ids
    
    def add_manual_association(self, memory_id_1: str, memory_id_2: str, strength: float = 1.0):
        """æ‰‹åŠ¨æ·»åŠ å…³è”"""
        return self.association_manager.add_association(memory_id_1, memory_id_2, strength)
    
    def get_associated_memories(self, memory_id: str, limit: int = 5):
        """è·å–å…³è”è®°å¿†"""
        associations = self.association_manager.get_associated_memories(memory_id, limit)
        results = []
        
        for assoc in associations:
            assoc_id = assoc["memory_id"]
            if assoc_id in self.memories:
                memory = self.memories[assoc_id].copy()
                memory["association_strength"] = assoc["strength"]
                results.append(memory)
        
        return results
    
    def export_data(self, format: str = "json"):
        """å¯¼å‡ºæ•°æ®"""
        return self.export_manager.export_memories(self.memories, format)
    
    def import_data(self, filepath: str, format: str = "json"):
        """å¯¼å…¥æ•°æ®"""
        imported_memories = self.export_manager.import_memories(filepath, format)
        
        for memory_id, memory in imported_memories.items():
            if memory_id not in self.memories:
                self.memories[memory_id] = memory
        
        self.save_memories()
        return len(imported_memories)
    
    def get_context_memories(self, query: str, limit: int = 3):
        """è·å–ä¸Šä¸‹æ–‡ç›¸å…³è®°å¿†ï¼ˆç”¨äºAIé›†æˆï¼‰"""
        relevant_memories = self.search_memories(query, limit=limit, use_semantic=True)
        
        context_text = "ç›¸å…³è®°å¿†ï¼š\n"
        for i, memory in enumerate(relevant_memories, 1):
            context_text += f"{i}. {memory['content']}\n"
        
        return context_text
    
    async def organize_with_model(self, model_id: str = None, tasks: List[str] = None) -> Dict[str, Any]:
        """ä½¿ç”¨AIæ¨¡å‹æ¢³ç†è®°å¿†"""
        if not self.organizer:
            return {"error": "Memory organizer not initialized"}
        
        # è·å–æ‰€æœ‰è®°å¿†
        all_memories = list(self.memories.values())
        
        if not all_memories:
            return {"error": "No memories to organize"}
        
        return await self.organizer.organize_memories(all_memories, model_id, tasks)
    
    def apply_organization_results(self, results: Dict[str, Any]) -> Dict[str, int]:
        """åº”ç”¨æ¢³ç†ç»“æœ"""
        applied_changes = {
            "categorization": 0,
            "importance_updates": 0,
            "associations_created": 0
        }
        
        try:
            # åº”ç”¨åˆ†ç±»å»ºè®®
            if "categorization" in results and isinstance(results["categorization"], list):
                for item in results["categorization"]:
                    if "memory_id" in item and "suggested_category" in item:
                        memory_id = item["memory_id"]
                        if memory_id in self.memories:
                            self.memories[memory_id]["type"] = item["suggested_category"]
                            applied_changes["categorization"] += 1
            
            # åº”ç”¨é‡è¦æ€§å»ºè®®
            if "importance_suggestions" in results and isinstance(results["importance_suggestions"], list):
                for item in results["importance_suggestions"]:
                    if "memory_id" in item and "suggested_importance" in item:
                        memory_id = item["memory_id"]
                        if memory_id in self.memories:
                            new_importance = float(item["suggested_importance"])
                            if 0 <= new_importance <= 1:
                                self.memories[memory_id]["importance"] = new_importance
                                applied_changes["importance_updates"] += 1
            
            # åº”ç”¨å…³è”å»ºè®®
            if "associations" in results and isinstance(results["associations"], list):
                for item in results["associations"]:
                    if "memory_id_1" in item and "memory_id_2" in item:
                        memory_id_1 = item["memory_id_1"]
                        memory_id_2 = item["memory_id_2"]
                        strength = float(item.get("relation_strength", 0.5))
                        
                        if memory_id_1 in self.memories and memory_id_2 in self.memories:
                            self.association_manager.add_association(memory_id_1, memory_id_2, strength)
                            applied_changes["associations_created"] += 1
            
            # ä¿å­˜æ›´æ”¹
            if any(applied_changes.values()):
                self.save_memories()
                self.association_manager.save_associations()
            
            return applied_changes
            
        except Exception as e:
            astrbot_logger.error(f"Failed to apply organization results: {e}")
            return applied_changes
    
    def get_available_models(self) -> Dict[str, Any]:
        """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
        if self.organizer:
            return self.organizer.get_available_models()
        return {}
    
    def get_stats(self):
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        total = len(self.memories)
        type_counts = {}
        
        for memory in self.memories.values():
            mem_type = memory.get('type', 'other')
            type_counts[mem_type] = type_counts.get(mem_type, 0) + 1
        
        avg_importance = sum(m.get('importance', 0) for m in self.memories.values()) / total if total > 0 else 0
        
        # å…³è”ç»Ÿè®¡
        total_associations = sum(len(v) for v in self.association_manager.associations.values())
        
        component_status = {
            "semantic_search": self.embedding_model is not None,
            "auto_extraction": True,
            "association_management": True,
            "data_import_export": True,
            "ai_integration": True,
            "ai_organization": self.organizer is not None
        }
        
        return {
            "total_memories": total,
            "type_counts": type_counts,
            "average_importance": avg_importance,
            "total_associations": total_associations,
            "component_status": component_status,
            "storage_path": self.storage_path
        }

@register(
    "enhanced_memory",
    "xingchenxiangyu", 
    "Enhanced memory plugin with AI-powered organization - å¢å¼ºè®°å¿†æ’ä»¶",
    "1.0.0"  # æ›´æ–°ç‰ˆæœ¬å·
)
class EnhancedMemoryPlugin(Star):
    def __init__(self, context: Context, config: Optional[Dict[str, Any]] = None):
        super().__init__(context)
        
        self.context = context
        self.config = config or {}
        self.conversation_history = []
        
        # ä¿®å¤å­˜å‚¨è·¯å¾„é—®é¢˜
        storage_config = self.config.get("storage_config", {})
        storage_path = storage_config.get("storage_path", "plugin_data/enhanced_memory")
        
        # ä½¿ç”¨AstrBotçš„æ•°æ®ç›®å½•ï¼Œä½†é¿å…é‡å¤çš„dataç›®å½•
        data_dir = getattr(context, 'data_dir', 'data')
        
        # å¦‚æœå­˜å‚¨è·¯å¾„å·²ç»æ˜¯ç»å¯¹è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™ä¸data_diræ‹¼æ¥
        if os.path.isabs(storage_path):
            self.storage_path = storage_path
        else:
            # æ£€æŸ¥å­˜å‚¨è·¯å¾„æ˜¯å¦å·²ç»åŒ…å«dataç›®å½•
            if storage_path.startswith('data/'):
                # å¦‚æœå·²ç»åŒ…å«data/å‰ç¼€ï¼Œç›´æ¥ä½¿ç”¨
                self.storage_path = os.path.join(data_dir, storage_path[5:])  # å»æ‰å‰é¢çš„"data/"
            else:
                # å¦åˆ™æ­£å¸¸æ‹¼æ¥
                self.storage_path = os.path.join(data_dir, storage_path)
        
        # è§„èŒƒåŒ–è·¯å¾„ï¼Œè§£å†³Windows/Unixè·¯å¾„åˆ†éš”ç¬¦é—®é¢˜
        self.storage_path = os.path.normpath(self.storage_path)
        
        self.memory_manager = None
        self._initialized = False
        self.auto_extract_enabled = self.config.get("auto_extraction", {}).get("enabled", True)
        self.organization_enabled = self.config.get("organization_config", {}).get("enabled", True)
        
        self._initialize_memory_manager()
        
        astrbot_logger.info("Enhanced Memory Plugin v1.0.0 initialized successfully")
        astrbot_logger.info(f"Storage path: {self.storage_path}")
        astrbot_logger.info(f"Auto extraction: {'Enabled' if self.auto_extract_enabled else 'Disabled'}")
        astrbot_logger.info(f"AI Organization: {'Enabled' if self.organization_enabled else 'Disabled'}")

    def _initialize_memory_manager(self):
        """åˆå§‹åŒ–å†…å­˜ç®¡ç†å™¨"""
        try:
            self.memory_manager = EnhancedMemoryManager(self.storage_path, self.context)
            self._initialized = True
            astrbot_logger.info("Memory manager initialized successfully")
        except Exception as e:
            astrbot_logger.error(f"Failed to initialize memory manager: {e}")
            self._initialized = False

    # ==================== äº‹ä»¶ç›‘å¬å™¨ ====================

    @filter.event_message_type(filter.EventMessageType.ALL)
    async def on_all_messages(self, event: AstrMessageEvent):
        """ç›‘å¬æ‰€æœ‰æ¶ˆæ¯ï¼Œç”¨äºè‡ªåŠ¨æå–è®°å¿† - ä¿®å¤é‡å¤è®°å¿†bug"""
        if not self._initialized or not self.auto_extract_enabled:
            return
        
        try:
            message_content = event.message_str
            
            # ğŸ”§ ä¿®å¤ï¼šè¿‡æ»¤å‘½ä»¤æ¶ˆæ¯ï¼Œé¿å…é‡å¤è®°å¿†
            if message_content.startswith('/'):
                return  # å¿½ç•¥æ‰€æœ‰å‘½ä»¤æ¶ˆæ¯
            
            user_id = event.get_sender_id()
            
            # æ›´æ–°å¯¹è¯å†å²
            self.conversation_history.append({
                "role": "user",
                "content": message_content,
                "user_id": user_id,
                "timestamp": datetime.now().isoformat()
            })
            
            # ä¿æŒå†å²é•¿åº¦
            if len(self.conversation_history) > 20:
                self.conversation_history = self.conversation_history[-20:]
            
            # è‡ªåŠ¨æå–è®°å¿†
            extracted_ids = self.memory_manager.auto_extract_from_message(
                message_content, 
                self.conversation_history
            )
            
            if extracted_ids:
                astrbot_logger.info(f"Auto extracted {len(extracted_ids)} memories from message")
                
        except Exception as e:
            astrbot_logger.error(f"Auto extraction failed: {e}")

    @filter.on_llm_request()
    async def on_llm_request(self, event: AstrMessageEvent, req: Any):
        """åœ¨LLMè¯·æ±‚å‰æ³¨å…¥ç›¸å…³è®°å¿†"""
        if not self._initialized:
            return
        
        try:
            # è·å–å½“å‰æ¶ˆæ¯å†…å®¹
            current_message = event.message_str
            
            # æœç´¢ç›¸å…³è®°å¿†
            context_memories = self.memory_manager.get_context_memories(current_message, limit=3)
            
            # å¦‚æœæœ‰ç›¸å…³è®°å¿†ï¼Œæ·»åŠ åˆ°ç³»ç»Ÿæç¤ºä¸­
            if context_memories and len(context_memories.strip()) > 20:  # ç¡®ä¿ä¸æ˜¯ç©ºå†…å®¹
                if hasattr(req, 'system_prompt'):
                    req.system_prompt = f"{req.system_prompt}\n\n{context_memories}"
                elif hasattr(req, 'messages') and req.messages:
                    # æ·»åŠ åˆ°ç³»ç»Ÿæ¶ˆæ¯
                    system_message = None
                    for msg in req.messages:
                        if msg.get('role') == 'system':
                            system_message = msg
                            break
                    
                    if system_message:
                        system_message['content'] = f"{system_message['content']}\n\n{context_memories}"
                    else:
                        req.messages.insert(0, {'role': 'system', 'content': context_memories})
                
                astrbot_logger.info("Injected relevant memories into LLM context")
                
        except Exception as e:
            astrbot_logger.error(f"Failed to inject memories into LLM context: {e}")

    # ==================== å‘½ä»¤å¤„ç†å™¨ ====================

    @filter.command("memo_add", aliases=["è®°å¿†æ·»åŠ ", "æ·»åŠ è®°å¿†"])
    async def memo_add_command(self, event: AstrMessageEvent, content: str):
        """æ·»åŠ è®°å¿†"""
        try:
            if not self._initialized:
                yield event.plain_result("âŒ è®°å¿†ç³»ç»Ÿæœªåˆå§‹åŒ–")
                return

            memory_id = self.memory_manager.add_memory(content)
            
            if memory_id:
                yield event.plain_result("âœ… è®°å¿†å·²æˆåŠŸæ·»åŠ ï¼")
            else:
                yield event.plain_result("âŒ æ·»åŠ è®°å¿†å¤±è´¥")
                
        except Exception as e:
            astrbot_logger.error(f"Error adding memory: {e}")
            yield event.plain_result("âŒ æ·»åŠ è®°å¿†æ—¶å‘ç”Ÿé”™è¯¯")

    @filter.command("memo_delete", aliases=["è®°å¿†åˆ é™¤", "åˆ é™¤è®°å¿†"])
    async def memo_delete_command(self, event: AstrMessageEvent, memory_id: str):
        """åˆ é™¤è®°å¿†"""
        try:
            if not self._initialized:
                yield event.plain_result("âŒ è®°å¿†ç³»ç»Ÿæœªåˆå§‹åŒ–")
                return

            if self.memory_manager.delete_memory(memory_id):
                yield event.plain_result("âœ… è®°å¿†å·²æˆåŠŸåˆ é™¤ï¼")
            else:
                yield event.plain_result("âŒ åˆ é™¤è®°å¿†å¤±è´¥ï¼Œè®°å¿†IDä¸å­˜åœ¨")
                
        except Exception as e:
            astrbot_logger.error(f"Error deleting memory: {e}")
            yield event.plain_result("âŒ åˆ é™¤è®°å¿†æ—¶å‘ç”Ÿé”™è¯¯")

@filter.command("memo_search", aliases=["è®°å¿†æœç´¢", "æœç´¢è®°å¿†"])
async def memo_search_command(self, event: AstrMessageEvent, query: str, limit: int = 5):
    """æœç´¢è®°å¿† - å¢å¼ºè°ƒè¯•ç‰ˆ"""
    try:
        if not self._initialized:
            yield event.plain_result("âŒ è®°å¿†ç³»ç»Ÿæœªåˆå§‹åŒ–")
            return

        astrbot_logger.info(f"å¼€å§‹æœç´¢: '{query}', é™åˆ¶: {limit}")
        
        # æ˜¾ç¤ºå½“å‰è®°å¿†æ€»æ•°
        total_memories = len(self.memory_manager.memories)
        astrbot_logger.info(f"å½“å‰è®°å¿†åº“æ€»æ•°: {total_memories}")
        
        results = self.memory_manager.search_memories(query, limit=limit, include_associated=True)
        
        if results:
            response = f"ğŸ” æ‰¾åˆ° {len(results)} æ¡ç›¸å…³è®°å¿† (å…±{total_memories}æ¡):\n\n"
            for i, memory in enumerate(results, 1):
                content = memory['content']
                mem_type = memory.get('type', 'æœªçŸ¥')
                importance = memory.get('importance', 0.5)
                match_type = memory.get('match_type', 'unknown')
                
                response += f"{i}. {content}\n"
                response += f"   ç±»å‹: {mem_type} | é‡è¦æ€§: {importance:.2f} | åŒ¹é…æ–¹å¼: {match_type}"
                
                if memory.get('similarity'):
                    response += f" | ç›¸ä¼¼åº¦: {memory['similarity']:.3f}"
                if memory.get('association_strength'):
                    response += f" | å…³è”å¼ºåº¦: {memory['association_strength']:.3f}"
                
                response += f" | ID: {memory['id'][:8]}...\n\n"
                
            yield event.plain_result(response)
        else:
            # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
            debug_info = f"âŒ æ²¡æœ‰æ‰¾åˆ°ç›¸å…³è®°å¿† (æœç´¢: '{query}')\n"
            debug_info += f"å½“å‰è®°å¿†åº“: {total_memories} æ¡è®°å¿†\n"
            debug_info += "ğŸ’¡ æç¤º: å°è¯•ä½¿ç”¨æ›´ç®€å•çš„å…³é”®è¯æˆ–æ£€æŸ¥è®°å¿†å†…å®¹"
            yield event.plain_result(debug_info)
            
    except Exception as e:
        astrbot_logger.error(f"æœç´¢è®°å¿†æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        yield event.plain_result(f"âŒ æœç´¢è®°å¿†æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        
    @filter.command("memo_associate", aliases=["è®°å¿†å…³è”", "å…³è”è®°å¿†"])
    async def memo_associate_command(self, event: AstrMessageEvent, memory_id_1: str, memory_id_2: str):
        """å…³è”è®°å¿†"""
        try:
            if not self._initialized:
                yield event.plain_result("âŒ è®°å¿†ç³»ç»Ÿæœªåˆå§‹åŒ–")
                return

            if self.memory_manager.add_manual_association(memory_id_1, memory_id_2):
                yield event.plain_result("âœ… è®°å¿†å…³è”å·²å»ºç«‹ï¼")
            else:
                yield event.plain_result("âŒ å…³è”è®°å¿†å¤±è´¥ï¼Œè¯·æ£€æŸ¥è®°å¿†ID")
                
        except Exception as e:
            astrbot_logger.error(f"Error associating memories: {e}")
            yield event.plain_result("âŒ å…³è”è®°å¿†æ—¶å‘ç”Ÿé”™è¯¯")

    @filter.command("memo_organize", aliases=["è®°å¿†æ¢³ç†", "æ¢³ç†è®°å¿†"])
    async def memo_organize_command(self, event: AstrMessageEvent, tasks: str = "all", model_id: str = None):
        """ä½¿ç”¨AIæ¨¡å‹æ¢³ç†è®°å¿†"""
        try:
            if not self._initialized:
                yield event.plain_result("âŒ è®°å¿†ç³»ç»Ÿæœªåˆå§‹åŒ–")
                return
            
            if not self.organization_enabled:
                yield event.plain_result("âŒ è®°å¿†æ¢³ç†åŠŸèƒ½æœªå¯ç”¨ï¼Œè¯·åœ¨é…ç½®ä¸­å¯ç”¨")
                return

            # è§£æä»»åŠ¡åˆ—è¡¨
            task_list = []
            if tasks == "all":
                task_list = ["categorize", "summarize", "find_duplicates", "suggest_associations", "suggest_importance"]
            else:
                task_list = [task.strip() for task in tasks.split(",")]
            
            # è·å–å¯ç”¨æ¨¡å‹
            available_models = self.memory_manager.get_available_models()
            if not available_models:
                yield event.plain_result("âŒ æ²¡æœ‰å¯ç”¨çš„AIæ¨¡å‹ï¼Œè¯·å…ˆé…ç½®LLMæä¾›å•†")
                return
            
            # æ˜¾ç¤ºæ¨¡å‹é€‰æ‹©
            model_info = ""
            if model_id and model_id in available_models:
                model_info = f"ä½¿ç”¨æ¨¡å‹: {available_models[model_id]['name']}"
            else:
                default_provider = self.context.get_using_provider()
                if default_provider:
                    model_info = f"ä½¿ç”¨é»˜è®¤æ¨¡å‹: {getattr(default_provider, 'name', 'Unknown')}"
                else:
                    model_info = "ä½¿ç”¨ç³»ç»Ÿé»˜è®¤æ¨¡å‹"
            
            yield event.plain_result(f"ğŸ”§ å¼€å§‹ä½¿ç”¨AIæ¢³ç†è®°å¿†...\n{model_info}\nä»»åŠ¡: {', '.join(task_list)}")
            
            # æ‰§è¡Œæ¢³ç†
            organization_results = await self.memory_manager.organize_with_model(model_id, task_list)
            
            if "error" in organization_results:
                yield event.plain_result(f"âŒ æ¢³ç†å¤±è´¥: {organization_results['error']}")
                return
            
            # æ˜¾ç¤ºæ¢³ç†ç»“æœ
            response = "ğŸ¯ AIæ¢³ç†ç»“æœï¼š\n\n"
            
            if "summary" in organization_results:
                response += f"ğŸ“ è®°å¿†åº“æ€»ç»“ï¼š\n{organization_results['summary']}\n\n"
            
            if "categorization" in organization_results:
                cat_count = len(organization_results['categorization'])
                response += f"ğŸ·ï¸ åˆ†ç±»å»ºè®®: {cat_count} æ¡\n"
            
            if "duplicates" in organization_results:
                dup_count = len(organization_results['duplicates'])
                response += f"ğŸ”„ é‡å¤æ£€æµ‹: {dup_count} å¯¹\n"
            
            if "associations" in organization_results:
                assoc_count = len(organization_results['associations'])
                response += f"ğŸ”— å…³è”å»ºè®®: {assoc_count} å¯¹\n"
            
            if "importance_suggestions" in organization_results:
                imp_count = len(organization_results['importance_suggestions'])
                response += f"â­ é‡è¦æ€§è°ƒæ•´: {imp_count} æ¡\n"
            
            response += "\nğŸ’¡ ä½¿ç”¨ /memo_apply_org åº”ç”¨è¿™äº›å»ºè®®"
            
            # ä¿å­˜æ¢³ç†ç»“æœä¾›åç»­åº”ç”¨
            self.last_organization_results = organization_results
            
            yield event.plain_result(response)
                
        except Exception as e:
            astrbot_logger.error(f"Error organizing memories: {e}")
            yield event.plain_result("âŒ è®°å¿†æ¢³ç†æ—¶å‘ç”Ÿé”™è¯¯")

    @filter.command("memo_apply_org", aliases=["åº”ç”¨æ¢³ç†", "åº”ç”¨å»ºè®®"])
    async def memo_apply_org_command(self, event: AstrMessageEvent):
        """åº”ç”¨æ¢³ç†ç»“æœ"""
        try:
            if not self._initialized:
                yield event.plain_result("âŒ è®°å¿†ç³»ç»Ÿæœªåˆå§‹åŒ–")
                return
            
            if not hasattr(self, 'last_organization_results') or not self.last_organization_results:
                yield event.plain_result("âŒ æ²¡æœ‰å¯åº”ç”¨çš„æ¢³ç†ç»“æœï¼Œè¯·å…ˆä½¿ç”¨ /memo_organize")
                return

            yield event.plain_result("ğŸ”„ æ­£åœ¨åº”ç”¨AIæ¢³ç†å»ºè®®...")
            
            applied_changes = self.memory_manager.apply_organization_results(self.last_organization_results)
            
            response = "âœ… å·²åº”ç”¨AIæ¢³ç†å»ºè®®ï¼š\n\n"
            if applied_changes["categorization"] > 0:
                response += f"â€¢ æ›´æ–°åˆ†ç±»: {applied_changes['categorization']} æ¡\n"
            if applied_changes["importance_updates"] > 0:
                response += f"â€¢ è°ƒæ•´é‡è¦æ€§: {applied_changes['importance_updates']} æ¡\n"
            if applied_changes["associations_created"] > 0:
                response += f"â€¢ æ–°å»ºå…³è”: {applied_changes['associations_created']} å¯¹\n"
            
            if not any(applied_changes.values()):
                response = "â„¹ï¸ æ²¡æœ‰éœ€è¦åº”ç”¨çš„æ›´æ”¹"
            
            # æ¸…ç†ç»“æœ
            del self.last_organization_results
            
            yield event.plain_result(response)
                
        except Exception as e:
            astrbot_logger.error(f"Error applying organization: {e}")
            yield event.plain_result("âŒ åº”ç”¨æ¢³ç†ç»“æœæ—¶å‘ç”Ÿé”™è¯¯")

    @filter.command("memo_models", aliases=["å¯ç”¨æ¨¡å‹", "æ¨¡å‹åˆ—è¡¨"])
    async def memo_models_command(self, event: AstrMessageEvent):
        """æ˜¾ç¤ºå¯ç”¨æ¨¡å‹"""
        try:
            if not self._initialized:
                yield event.plain_result("âŒ è®°å¿†ç³»ç»Ÿæœªåˆå§‹åŒ–")
                return

            available_models = self.memory_manager.get_available_models()
            
            if not available_models:
                yield event.plain_result("âŒ æ²¡æœ‰å¯ç”¨çš„AIæ¨¡å‹ï¼Œè¯·å…ˆé…ç½®LLMæä¾›å•†")
                return
            
            response = "ğŸ¤– å¯ç”¨AIæ¨¡å‹ï¼š\n\n"
            
            for model_id, model_info in available_models.items():
                response += f"â€¢ {model_id}: {model_info['name']}\n"
            
            response += "\nğŸ’¡ ä½¿ç”¨ /memo_organize model_id=æ¨¡å‹ID æŒ‡å®šä½¿ç”¨çš„æ¨¡å‹"
            
            yield event.plain_result(response)
                
        except Exception as e:
            astrbot_logger.error(f"Error listing models: {e}")
            yield event.plain_result("âŒ è·å–æ¨¡å‹åˆ—è¡¨æ—¶å‘ç”Ÿé”™è¯¯")

    @filter.command("memo_export", aliases=["è®°å¿†å¯¼å‡º", "å¯¼å‡ºè®°å¿†"])
    async def memo_export_command(self, event: AstrMessageEvent, format: str = "json"):
        """å¯¼å‡ºè®°å¿†"""
        try:
            if not self._initialized:
                yield event.plain_result("âŒ è®°å¿†ç³»ç»Ÿæœªåˆå§‹åŒ–")
                return

            filepath = self.memory_manager.export_data(format)
            
            if filepath:
                yield event.plain_result(f"âœ… è®°å¿†å·²å¯¼å‡ºåˆ°ï¼š{filepath}")
            else:
                yield event.plain_result("âŒ å¯¼å‡ºè®°å¿†å¤±è´¥")
                
        except Exception as e:
            astrbot_logger.error(f"Error exporting memories: {e}")
            yield event.plain_result("âŒ å¯¼å‡ºè®°å¿†æ—¶å‘ç”Ÿé”™è¯¯")

    @filter.command("memo_import", aliases=["è®°å¿†å¯¼å…¥", "å¯¼å…¥è®°å¿†"])
    async def memo_import_command(self, event: AstrMessageEvent, filepath: str, format: str = "json"):
        """å¯¼å…¥è®°å¿†"""
        try:
            if not self._initialized:
                yield event.plain_result("âŒ è®°å¿†ç³»ç»Ÿæœªåˆå§‹åŒ–")
                return

            count = self.memory_manager.import_data(filepath, format)
            
            if count > 0:
                yield event.plain_result(f"âœ… æˆåŠŸå¯¼å…¥ {count} æ¡è®°å¿†ï¼")
            else:
                yield event.plain_result("âŒ å¯¼å…¥è®°å¿†å¤±è´¥æˆ–æ²¡æœ‰æ–°è®°å¿†å¯å¯¼å…¥")
                
        except Exception as e:
            astrbot_logger.error(f"Error importing memories: {e}")
            yield event.plain_result("âŒ å¯¼å…¥è®°å¿†æ—¶å‘ç”Ÿé”™è¯¯")

    @filter.command("memo_stats", aliases=["è®°å¿†ç»Ÿè®¡", "è®°å¿†çŠ¶æ€"])
    async def memo_stats_command(self, event: AstrMessageEvent):
        """è®°å¿†ç»Ÿè®¡"""
        try:
            if not self._initialized:
                yield event.plain_result("âŒ è®°å¿†ç³»ç»Ÿæœªåˆå§‹åŒ–")
                return

            stats = self.memory_manager.get_stats()
            
            response = "ğŸ“Š è®°å¿†ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯ï¼š\n\n"
            response += f"â€¢ æ€»è®°å¿†æ•°é‡: {stats['total_memories']} æ¡\n"
            response += f"â€¢ æ€»å…³è”æ•°é‡: {stats['total_associations']} ä¸ª\n"
            response += f"â€¢ å­˜å‚¨è·¯å¾„: {stats['storage_path']}\n"
            response += f"â€¢ å¹³å‡é‡è¦æ€§: {stats['average_importance']:.2f}\n"
            
            if stats.get('type_counts'):
                response += "\nğŸ“ è®°å¿†ç±»å‹åˆ†å¸ƒï¼š\n"
                for mem_type, count in stats['type_counts'].items():
                    response += f"  â€¢ {mem_type}: {count} æ¡\n"
            
            if stats.get('component_status'):
                response += "\nâš™ï¸ ç»„ä»¶çŠ¶æ€ï¼š\n"
                comp_status = stats['component_status']
                response += f"  â€¢ è¯­ä¹‰æœç´¢: {'âœ…' if comp_status.get('semantic_search') else 'âŒ'}\n"
                response += f"  â€¢ è‡ªåŠ¨æå–: {'âœ…' if comp_status.get('auto_extraction') else 'âŒ'}\n"
                response += f"  â€¢ å…³è”ç®¡ç†: {'âœ…' if comp_status.get('association_management') else 'âŒ'}\n"
                response += f"  â€¢ æ•°æ®å¯¼å…¥å¯¼å‡º: {'âœ…' if comp_status.get('data_import_export') else 'âŒ'}\n"
                response += f"  â€¢ AIé›†æˆ: {'âœ…' if comp_status.get('ai_integration') else 'âŒ'}\n"
                response += f"  â€¢ AIæ¢³ç†: {'âœ…' if comp_status.get('ai_organization') else 'âŒ'}\n"
            
            yield event.plain_result(response)
            
        except Exception as e:
            astrbot_logger.error(f"Error getting stats: {e}")
            yield event.plain_result("âŒ è·å–ç»Ÿè®¡ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯")

    @filter.command("memo_deps", aliases=["è®°å¿†ä¾èµ–", "ä¾èµ–æ£€æŸ¥"])
    async def memo_deps_command(self, event: AstrMessageEvent):
        """ä¾èµ–æ£€æŸ¥"""
        deps_info = "ğŸ”§ ä¾èµ–æ£€æŸ¥ç»“æœï¼š\n\n"
        
        dependencies = {
            'faiss': 'å‘é‡æœç´¢',
            'sentence_transformers': 'è¯­ä¹‰åµŒå…¥', 
            'jieba': 'ä¸­æ–‡åˆ†è¯'
        }
        
        for dep, desc in dependencies.items():
            try:
                __import__(dep)
                status = "âœ… å¯ç”¨"
            except ImportError:
                status = "âŒ ä¸å¯ç”¨"
            deps_info += f"â€¢ {dep} ({desc}): {status}\n"
        
        deps_info += "\nğŸ’¡ å®‰è£…å‘½ä»¤: pip install faiss-cpu sentence-transformers jieba"
        deps_info += "\n\nğŸ¯ å½“å‰åŠŸèƒ½: è‡ªåŠ¨æå– âœ… | è®°å¿†å…³è” âœ… | æ•°æ®å¯¼å…¥å¯¼å‡º âœ… | AIé›†æˆ âœ… | AIæ¢³ç† âœ…"
        
        yield event.plain_result(deps_info)

    @filter.command("memo_help", aliases=["è®°å¿†å¸®åŠ©"])
    async def memo_help_command(self, event: AstrMessageEvent):
        """å¸®åŠ©å‘½ä»¤"""
        help_text = """
ğŸ¤– å¢å¼ºè®°å¿†æ’ä»¶ v1.0.0 - AIæ™ºèƒ½æ¢³ç†ç‰ˆ

ğŸ“ è®°å¿†ç®¡ç†ï¼š
/memo_add [å†…å®¹] - æ·»åŠ è®°å¿†
/memo_delete [è®°å¿†ID] - åˆ é™¤è®°å¿†  
/memo_search [å…³é”®è¯] [æ•°é‡] - æœç´¢è®°å¿†

ğŸ”— è®°å¿†å…³è”ï¼š
/memo_associate [è®°å¿†ID1] [è®°å¿†ID2] - æ‰‹åŠ¨å…³è”è®°å¿†

ğŸ¤– AIæ¢³ç†ï¼š
/memo_organize [ä»»åŠ¡] [æ¨¡å‹ID] - ä½¿ç”¨AIæ¢³ç†è®°å¿†
/memo_apply_org - åº”ç”¨æ¢³ç†å»ºè®®
/memo_models - æŸ¥çœ‹å¯ç”¨æ¨¡å‹

ğŸ“Š æ•°æ®ç®¡ç†ï¼š
/memo_export [æ ¼å¼] - å¯¼å‡ºè®°å¿† (json/csv)
/memo_import [æ–‡ä»¶è·¯å¾„] [æ ¼å¼] - å¯¼å…¥è®°å¿†

ğŸ“ˆ ç³»ç»Ÿä¿¡æ¯ï¼š
/memo_stats - æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
/memo_deps - æ£€æŸ¥ä¾èµ–çŠ¶æ€

â“ æ˜¾ç¤ºå¸®åŠ©ï¼š
/memo_help - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯

ğŸ¯ AIæ¢³ç†ä»»åŠ¡ï¼š
â€¢ categorize - é‡æ–°åˆ†ç±»è®°å¿†
â€¢ summarize - æ€»ç»“è®°å¿†åº“
â€¢ find_duplicates - æ£€æµ‹é‡å¤è®°å¿†
â€¢ suggest_associations - å»ºè®®å…³è”
â€¢ suggest_importance - è°ƒæ•´é‡è¦æ€§

ğŸ’¡ ç¤ºä¾‹ï¼š
/memo_organize all
/memo_organize categorize,suggest_associations
/memo_organize all model_id=your_model_id
/memo_apply_org
"""
        yield event.plain_result(help_text)

    async def terminate(self):
        """æ’ä»¶åœæ­¢æ—¶çš„æ¸…ç†å·¥ä½œ"""
        astrbot_logger.info("Enhanced Memory Plugin v1.0.0 is shutting down...")
        try:
            if self._initialized and hasattr(self.memory_manager, 'save_memories'):
                self.memory_manager.save_memories()
                astrbot_logger.info("Memories saved successfully")
        except Exception as e:
            astrbot_logger.error(f"Error saving memories during shutdown: {e}")